% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%

\documentclass[english]{sig-alternate-05-2015}



\usepackage{babel}
\usepackage{csquotes}
\MakeOuterQuote{"}

%\usepackage[backend=biber,style=numeric-comp]{biblatex}
%\bibliography{references}
%\renewcommand{\bibliography}[1]{\printbibliography}

\usepackage{MnSymbol}

\usepackage[svgnames]{xcolor}
%\usepackage{todonotes}
%\presetkeys{todonotes}{inline}{}
\usepackage[subject={TODO}]{pdfcomment}
\newcommand{\todo}[2][]{\pdfmargincomment[author={#1}]{#2}}

%\usepackage{makecell}
\usepackage{ctable}


\usepackage{listings}

\newcommand{\lineref}[2]{\hyperref[#1]{line~\ref*{#1:#2}}}
\newcommand{\linerefn}[2]{\hyperref[#1]{line~#2}}
\newcommand{\linesrefn}[2]{\hyperref[#1]{lines~#2}}
\usepackage{accsupp}
\newcommand\emptyaccsupp[1]{\BeginAccSupp{ActualText={}}#1\EndAccSupp{}}

\usepackage{hyperref}
\usepackage[all]{hypcap}
\PassOptionsToPackage{nameinlink,noabbrev}{cleveref}
\usepackage{cleveref}


% \lstset{captionpos=b, xleftmargin=1cm}
\lstset{basicstyle=\small\ttfamily}
\lstset{showstringspaces=false, columns=flexible, keepspaces=true}
\lstset{tabsize=2, gobble=2}
%\lstset{upquote=true}
%% Linebreaks
%\lstset{prebreak=\raisebox{0ex}[0ex][0ex]
%        {\ensuremath{\rhookswarrow}}}
\lstset{postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\rcurvearrowse\space}}}
\lstset{breaklines=true, breakatwhitespace=true}
%% Line Numbers
\newcommand{\lstnumberstyle}[1]{\tiny\emptyaccsupp{#1}}
\lstset{numbers=left, numberstyle=\lstnumberstyle, numbersep=5pt,
		numberfirstline=true, firstnumber=1, stepnumber=5}
\lstset{escapeinside={(*@}{@*)}}
\lstdefinestyle{BWStyle}{
	keywordstyle=\bfseries,
	stringstyle=\color{DimGray},
	commentstyle=\textsl,
}
\lstset{style=BWStyle}

\lstdefinelanguage{algorithm}{
	keywords={function, for, do, if, then, else, return, in_, is_a, or, and},
	morecomment=[l]{'},
	morecomment=[s]{/*}{*/},
	morestring=[b]",  
	sensitive=true,
}
\lstdefinelanguage{HanaSQL}[]{SQL}{
	morekeywords={replace,string,if,is,daysbetween,secondsbetween,weekday,adddays,addseconds,double, procedure,begin,declare,inout,call,return,returns},
	moredelim=**[is][\slshape]{^}{^},
	moredelim=**[is][\bfseries]{§}{§},
}
\lstdefinelanguage{Inline}{
	moredelim=**[is][\slshape]{^}{^},
	moredelim=**[is][\bfseries]{§}{§},
}

\lstset{language=HanaSQL}
\lstMakeShortInline[basicstyle=\ttfamily,language={Inline},breaklines=true]°

%Macros
\newcommand{\tool}{TARDISP}
\newcommand{\SQLextension}{TARDISQL}


\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\doi{TBD}

% ISBN
\isbn{TBD}

%Conference
\conferenceinfo{SANER '17}{February 20--24, 2017, Klagenfurt, Austria}

\acmPrice{TBD}

%
% --- Author Metadata here ---
\conferenceinfo{SANER Industry Track}{2017 Klagenfurt, Austria}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{Bringing Back-in-Time Debugging down to the Database}
%\subtitle{(\tool is a placeholder for the actual name)}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} 
\author{
% 1st. author
\alignauthor
Arian Treffer\\
       \affaddr{Hasso-Plattner-Institut}\\
       \affaddr{Potsdam, Germany}\\
       \affaddr{arian.treffer@hpi.de}
% 2nd. author
\alignauthor
Michael Perscheid\\
       \affaddr{SAP Innovation Center}\\
       \affaddr{Potsdam, Germany}\\
       \affaddr{michael.perscheid@sap.com}
% 3rd. author
\alignauthor 
Matthias Uflacker\\
       \affaddr{Hasso-Plattner-Institut}\\
       \affaddr{Potsdam, Germany}\\
       \affaddr{matthias.uflacker@hpi.de}
%\and  % use '\and' if you need 'another row' of author names
}

%\date{30 July 1999}

\maketitle
\begin{abstract}
Back-in-time debuggers allow developers to explore what happened before a failure and so support them in finding failure causes more efficiently. 
However, if failure causes leave a specific application layer, it is difficult to further follow infections down to the real defect.
Especially at the database-level, developers have no such debugging tools to understand unexpected behavior comprehensively.

In this paper, we present an approach for bringing back-in-time debugging down to SQL and stored procedures of the SAP HANA in-memory database.
Our \tool\, debugger allows developers to step queries backwards and inspecting the database at previous and arbitrary points in time.
With the help of a SQL extension, we can express queries covering a period of execution time within a debugging session and handle large amounts of data with low overhead on performance and memory.
The entire approach has been evaluated within a development project at SAP and shows promising results with respect to the gathered developer feedback.

\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

%\printccsdesc

\keywords{Back-in-time debugging, in-memory database, SAP HANA}

%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\section{Introduction}

%Context: Debugging and Back-in-Time
Finding defects in code is a frequent task for every programmer and is often difficult even with a deep understanding of the system.
To localize failure causes, they examine involved program entities and distinguish relevant from irrelevant behavior and clean from infected state. 
However, common symbolic debuggers do not support identification of such infection chains very well because they only provide access to the last point of execution without access to the program history.
Back-in-time also known as omniscient debuggers simplify the debugging process \todo{cite} by making it easier to follow cause-effect chains from the observable failure back to the causing defect.
These tools provide full access to past events so that developers can directly experiment with the entire infection chain. 

%Problem: Back-in-time debugger missing for database-level
Even though back-in-time debuggers exist for many object-oriented programming languages\todo{cite}, there are none to the best of our knowledge that run on databases and support SQL or SQLScript\footnote{SQLScript is a proprietary SQL extension for stored procedures in SAP HANA~\cite{sqlScript}.}.
This is mainly because of two reasons. 
First, back-in-time debuggers typically create a significant overhead on performance and memory consumption\todo{cite}.
It seems unfeasible to use a back-in-time debugger on top of a database script that processes billions of records.
Second, current back-in-time debugging concepts cannot handle side-effects outside their system that usually happen in writing operations during INSERT and UPDATE statements. 

%Significance: Especially, in business software much development is based on database scripts. 
Due to high performance requirements of handling big data in business applications, SAP has not only a strong demand to move code closer to data~\cite{plattner2015memory} but also the need to improve development tools at the database-level. 
As existing tools mostly work on the application level, are limited to specific points in time, or work only on a query plan, developers are often left alone when it comes to debug and understand the results of their SQL and SQLScripts.
We argue that a back-in-time debugger at the bottom of the technology stack is able to close this gap and would support developers in developing and maintaining their queries more efficiently. 

%Solution
In this paper, we bring the concept of back-in-time debugging to the database and present \emph{\tool} as an implementation of our approach.
The contributions of this paper are as follows:
\begin{itemize}
	\item \emph{\tool} is a back-in-time debugger for stored procedures which can be installed in the SAP HANA in-memory database and programming platform.
		Using \tool, developers can move freely through the execution time of a stored procedure and inspect control flow, variables, and intermediate results.
	
	\item \emph{\SQLextension} is an extension to SQL allowing to submit arbitrary queries against previous states of the database 
		and to compare multiple points in time with one query.
		\tool\, provides a console for developers to submit \SQLextension\, queries which use variables or points in time from the current debug session.

	\item \emph{Very low overhead} when recording run-time data and the efficient querying of past database states allow developers to use \tool\, as the default tool for debugging database scripts even on larger data sets.
	
\end{itemize}

We evaluated \tool\, with the help our SAP colleagues who worked on a project called \emph{Point of Sales Explorer}~\cite{plattner2015memory} which makes heavy use of SQLScript. 
The interviews indicated that bugs in stored procedures can be investigated more efficiently with \tool\, than with existing other database development tools.

The remainder of this paper is structured as follows:
\Cref{sec:relatedWork} describes related work. 
\Cref{sec:prototype} presents our approach and its prototypical implementation of back-in-time debugging in the database.
\Cref{sec:ttqueries} discusses querying past database states and introduces and extension to SQL.
\Cref{sec:evaluation} evaluates our approach before \cref{sec:conclusion} discusses future work and concludes the paper.

%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\section{Related Work}
\label{sec:relatedWork}

%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


\section{Back-in-time Debugging for\\ Stored Procedures}
\label{sec:prototype}

% why post mortem
\todo{Add our tool name here and there in the following sections}
\todo{If we need to shorten later on, I would start here in the problem description.}

With a regular debugger, developers have only one way to go back in time, which is to restart the execution.
Tools can be used to automate this approach\todo{cite} and some modern debuggers even allow to restart execution at the method level\todo{cite}.
However, this approach fails if the code has side effects, as it can no longer be guaranteed to execute in the same way.
Furthermore, if the execution is too slow, developers will spend much time waiting for re-execution, which discourages the use of backwards stepping.

A different way to examine a program's behavior over time is to record a trace of the program's actions.
After the program terminated, the trace can be examined in a post-mortem analysis.
This works well for special purpose tools that only analyze a specific aspect of a program, such as profilers.
A post-mortem debugger, on the other hand, has to record virtually everything to be able to replay the program execution.
While this approach allows developers the most freedom when stepping through the execution, it creates a large overhead on performance and memory.
Debugger implementations using this approach exist for different programming languages.
%
Both approaches can also be mixed to create a tradeoff between performance and overhead\todo{cite}.

% post-mortem has been solved before, why is it harder in the database
When debugging programs that run on a database, a back-in-time debugger faces two additional problems:
First, the program's behavior strongly depends on external state.
With live debugging, this sometimes can be mitigated by resetting the database before restarting the program, but a post-mortem analysis can not easily examine intermediate states when they have been changed.
Second, much of the data processing happens outside of the program's scope.
Sometimes, state that has impact on a query's result even remains entirely in the database and is practically invisible to analysis tools.
The only way to examine such state is through specific database queries before it is changed.

Stored procedures add the additional challenge that results of a query can be used in subsequent database statements without having been fetched into the program.
This increases the amount of "invisible" state, sometimes only for a few instructions, other times for the entire length of the program.
Furthermore, as trace data usually exceeds program data by orders of magnitude, we expect that tracing the processing of every tuple in a large database is not feasible.

With \tool, we focuses on stored procedures because they are executed close to the data and, thus, more efficient in handling large data sets.
This does not limit the general validity of our results, as a stored procedures debugger faces all of the challenges described above.

\subsection{Replaying a Stored Procedure}

While using a database to manage application state creates several problems for debugging tools, it also opens up new possibilities to simplify or improve the debugger.

First, the database persists state beyond the program execution.
Even post-mortem, the state can be directly accessed by the debugger.

Second, all instructions handling large data sets (i.e., SQL statements), are declarative.
This means they can be analyzed without knowing how they are physically executed and results are reproducible as long as the underlying data does not change.
%Thus, SQL queries don't have to be traced at all, although for some purposes it will be helpful to record some meta information, such as the execution time or the number of results.
Thus, neither do we need to trace the internals of a query's execution, nor do we need to persist the query result.
\todo{MP: This is not clear to me, yet.}

Third, the database can be used to efficiently manage old state.
In-memory databases with insert-only storage automatically retain old data~\cite{Plattner2009Acd}.
With insert-only, older versions of the database can be easily reproduced.
For other database, insert-only can be achieved by adding validity columns.
For many business applications, the columns already exist as no data may be deleted for legal reasons.

In conclusion, all that is needed to reproduce the execution of a stored procedure is a sequence of execution steps.
Each step represents an instruction that has side effects on the database or assigns a value or result set to a variable.
As there is, conceptually, no concurrency in a stored procedure, we can use sequential numbering to track the order of steps.

If applicable, a step has a target name, e.g., the name of a variable or stored procedure, and a string representation of the value, which can be shown to the user in the debug view.
If the step involves a database statement, we only need a timestamp to be able to reproduce the query.
Moreover, we also record the number of rows in the result set and the execution time, as well as any atomic argument values, as this information is likely to be relevant for developers.

%We never trace any details of the query execution but only record the name of a view than can be used to later reproduce the query result.
%The view was specifically generated by the debugger, as will be explained in the next subsection.

%\subsection{Reproducing Query Results}

With the recorded trace data, the debugger has enough information available to replay the execution and to re-execute any query.
%
%However, the query will only yield the same results as long as the underlying data has not changed.
%
%In general, one can expect that debugging will take place on a development machine where no other data manipulation occurs.
%However, in cases where this assumption doesn't hold, the debugger might end up showing wrong or misleading data the developer.
%Furthermore, the debugged stored procedure itself may change the data, which will cause a query to return different results at different points in time.
%
%We ensure consistency over time by following the insert-only approach of our in-memory database.
%If we require for all tables that data can never be changed or deleted and annotate all tuples with timestamps of when they have been created and invalidated, we can reconstruct the state of the database of any point in time.
%Adding timestamp filters to select queries does not cause a significant slowdown.
%Our prototype was built using this approach.

\todo{HANA hat seit neustem "History tables" die das direkt können, wir benutzen aber explizite timestamps weil das momentan noch praktischer ist }


\subsection{Prototype and Tracing Code Generation}

We developed \tool\ as a prototype implementation of our approach.
Our back-in-time debugger runs in the SAP HANA XS-Engine, a framework for web-applications that is part of the SAP HANA platform.
The user interface is written in HTML5 and JavaScript and queries debugging data via HTTP from the back-end, written in server-side JavaScript.
Traces are stored directly in the database.
Packaged as a XS Application, \tool\ can be directly deployed in a SAP HANA installation.

%With a debugger fully integrated in its database, we would expect the stored procedure execution engine to trace the execution steps.
%However, for our prototype this level of integration was out of scope.\todo{Don't start this way but rather put it into limitation discussion or next steps in summary and than call it producterization}

To be able to trace an execution, we developed a SQLScript pre-processor that parses a stored procedure and adds °INSERT° statements around every instruction to collect the required trace data.
To obtain a trace, the debugger then once has to run the traced code instead of the original procedure.

In addition to the tracing code, the pre-processor also generates SQL functions and views that will be used to obtain variable values at given points in time.
For atomic variables, it is simply a search for its most recent step.

For variables containing result tables, a separate view is generated for each query that assigns to that variable.
Each view contains the original code of its query.
Arguments to the query are initialized using their respective views.
On top of that, a master view is generated that chooses the appropriate query view by looking up the requested step in the recorded trace.
\todo{AT: How much detail?}

The user interface looks like a typical debugger.\todo{Please add a screenshot and describe with it!}
The largest part of the screen shows the code.
Buttons allow the developer to step forwards and backwards.
Instead of a stack trace, \tool\ shows a tree of all execution steps.

Next to the code, current variable values are shown.
Arrow buttons allow to jump to the previous or next assignment of the variable.
For variables containing a query result, the size of the result is shown.
Clicking the variable opens a query window that shows the variable's content and allows the developer to submit time-travel queries, which will be explained in the next section.


%\begin{lstlisting}[language=HanaSQL,float,caption={Example procedure},label=lst:example]
	%CREATE PROCEDURE Check_Projects_Of_Department(dep_name VARCHAR(100)) AS
	%BEGIN
		%DECLARE dep_id INTEGER := SELECT id FROM Deparments WHERE name = :dep_name;
		%selected_projects := SELECT id FROM Projects WHERE deparment = :dep_id;
		%CALL Check_Projects(:selected_projects);
	%END
%\end{lstlisting}

%\begin{lstlisting}[language=HanaSQL,float,caption={Procedure with tracing},label=lst:example2]
	%CREATE PROCEDURE _T__Check_Projects_Of_Department (IN __t_id INT, IN __ce_id INT, INOUT __s_id INT, dep_name VARCHAR(100)) AS
	%BEGIN
		%DECLARE __e_id INT := __s_id+1;
		%DECLARE __ts TIMESTAMP;
		%DECLARE __count INT;
%
		%DECLARE dep_id INTEGER := SELECT id FROM Deparments WHERE name = :dep_name;
		%/*  1*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id+1,:__ce_id,'ENTER', 'Check_Projects_Of_Department',NULL,1);
		%/*  1*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id+1,:__e_id,'VARIABLE', 'dep_name',:dep_name,1);
		%/*  3*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id+2,:__e_id,'VARIABLE',  'dep_id',:dep_id,3);
		%__s_id := __s_id + 3;
		%/*  4*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id,:__e_id,'QUERY', 'selected_projects','selected_projects := SELECT id FROM Projects WHERE deparment = :dep_id;',4);
		%/*   */ __ts := NOW();
		%selected_projects := SELECT id FROM Projects WHERE deparment = :dep_id;
		%/*   */ SELECT COUNT(*) INTO __count FROM :selected_projects;
		%/*  4*/ INSERT INTO Quid_Accidit.Queries (trace_id,step,query,count,pre,post) VALUES (:__t_id,:__s_id, '_selected_projects_4_Check_Projects_Of_Department', __count,__ts,NOW());
		%__s_id := __s_id + 1;
		%/*  5*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id,:__e_id,'CALL', '?','Check_Projects',5);
		%CALL _T__Check_Projects(__s_id, :selected_projects);
	%END;
%
	%CREATE PROCEDURE _TE_Check_Projects_Of_Department (dep_name VARCHAR(100)) AS
	%BEGIN
		%DECLARE __t_id INT;
		%DECLARE __s_id INT DEFAULT 0;
		%SELECT COALESCE(MAX(id),0)+1 INTO __t_id FROM Quid_Accidit.Traces;
		%INSERT INTO Quid_Accidit.Traces(id, name) VALUES (:__t_id, 'Check_Projects_Of_Department');
		%CALL _T__Check_Projects_Of_Department (:__t_id, 0, __s_id, dep_name);
	%END;
%\end{lstlisting}

%
%\begin{lstlisting}[language=HanaSQL,float,caption={Example query in line 4 of "Check\_Projects"},label=lst:example3]
	%selected_projects := SELECT p.id FROM Projects p WHERE p.deparment = :dep_id;
%\end{lstlisting}
%
%\begin{lstlisting}[language=HanaSQL,float,caption={Query view},label=lst:example4]
	%CREATE FUNCTION 
			%_Q__Check_Projects_selected_projects_4_ 
			%(IN trace_id INT, IN step INT)
	%RETURNS TABLE(id INT) 
			%LANGUAGE SQLSCRIPT AS
	%BEGIN
		%DECLARE __ts TIMESTAMP := 
				%SELECT before FROM Queries q 
				%WHERE q.trace_id = :trace_id 
				  %AND q.step = :step;
		%DECLARE dep_id INT := SELECT 
				%_V__Check_Projects_dep_id_(:trace_id, :step) 
				%FROM DUMMY;
		%RETURN SELECT p.id FROM Projects p
				%WHERE p.deparment = :dep_id
				  %AND p.created_on < __ts
					%AND (p.valid_until IS NULL 
					   %OR p.valid_until > __ts);
	%END;
%\end{lstlisting}

%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\section{Time-travel Queries}
\label{sec:ttqueries}

In our setup, the debugger has to recreate intermediate results of a stored procedure.
We generalized this feature to enable developers to submit arbitrary queries against the database of any previous point in time.
Furthermore, we allow developers to compare query results from different points in time and even query for changes in the data.
We defined \SQLextension, a super-set of SQL that allows developers to refer to points in execution time by introducing a new keyword and a new operator.

As an example, we consider a stored procedure that processes purchase orders.
Users reported a bug: projects sometimes exceed their budget, which is not supposed to happen.

\todo{More intro needed especially for used examples. Furthermore, Listing 2 is not referenced and used from text.}

\subsection{The Step Concept}

The query shown in \cref{lst:ttravel} selects the total of open orders for previously selected projects.
We will use it as an example to demonstrate how \emph{time-traveling} queries are handled by our system.\todo{add our name instead our system}

\begin{lstlisting}[language=HanaSQL,float,caption={Example for a time-travel query: select the current total of open orders for previously selected projects},label=lst:ttravel]
  SELECT pr.id, pr.name, pr.budget, SUM(po.total)
  FROM :selected_projects pr
	JOIN PurchaseOrders po ON po.project_id = pr.id
	WHERE po.status = 'open'
	GROUP BY pr.id, pr.name, pr.budget
	^§AT STEP§ 1623^
\end{lstlisting}

The last line shows an extension to SQL that can be used by the developer to explicitly query a point in time, with °^1623^° being a step ID that was obtained from the debugger UI.\todo{Where does 1623 comes from?}
If omitted, the current step can be derived from the context from which the query is submitted, such as an SQL console that is associated with a specific point in time or the current debug step.
The parameter °:selected_projects° refers to a variable from the current debug session and will be populated with its current value, independently of the value of the step-clause.

When submitted, our debugger applies two changes to the query before it can be submitted to the database.
First, all variables are replaced with corresponding functions or views.
For variables containing atomic values, a function is generated that returns the variable's value at a given step.
For variables containing query results, a view is generated for each query.
These views are identified by the target variable name and the line number and expect a step number and all parameters that the actual query took.
\todo{explain variable functions}
In our example, °:selected_projects° might be replaced with °VAR_selected_projects_7(1055, 'Research')° when it was last set at step 1055 in code line 7 and called with the respective argument.

Second\todo{where is first?}, a time-stamp filter is added for all tables that are referenced in the query. 
In our example,
\begin{lstlisting}[language={Inline},basicstyle=\ttfamily,numbers=none]
  po.createdOn < ^1623^ AND (po.validTo IS NULL OR po.validTo > ^1623^)
\end{lstlisting}
would be added to the Where-clause.

Now, the query can be submitted to the database and the result is subsequently presented to the user.

\subsection{Time-diff Queries}

\newcommand{\red}[1]{\textcolor{DarkRed}{#1}}
\newcommand{\gr}[1]{\textcolor{Green}{#1}}


\ctable[star,caption={Result of a time-diff query, with multiple values in some columns},label=tab:diffresult,doinside={}]
				{rlrrrlr}{}{
	pr.id & pr.name 	& pr.budget & total & po2.id & po2.status & po2.total \ML
	
				&					 & \red{1200} & \red{1500} &	 & \red{open} &						\NN
	1			& Project 1 & 200				& 500 			 & 1 & paid 			& 1000			\NN
				&						& \gr{-300} & \gr{0}		 &	 &						&						\ML

				&					 & \red{1200} & \red{1500} &	 & 						&						\NN
	1			& Project 1 & 200				& 500 			 & 2 & open 			& 500				\NN
				&						& \gr{-300} & \gr{0}		 &	 & \gr{paid}	&						\ML
}

To get a better overview about what happened in a piece of code, the developer might want to query multiple points in time at once and see the difference in the query result.\todo{explain example - fix gender issue by talking plural!}
For this example, she debugs a stored procedure that processes the payments for projects, but sometimes allows projects to go over budget.
By stepping into the procedure, she has three defined points in time: °^before^°, at the beginning of the procedure; °^now^°, at the current instruction; and °^after^°, at the end of the execution.

Now she wants to compose a query that selects all projects that will go over budget and the orders that were processed.
\todo{explain query rewriting}
The query is shown in \cref{lst:tdiff}.
\begin{lstlisting}[language=HanaSQL,float=b,caption={Example of a time-diff query: "Select all projects that will go over budget and their respective purchase orders"},label=lst:tdiff]
	SELECT pr.id, pr.name, pr.budget, SUM(po.total), po2.id, po2.status, po2.total
	FROM :selectedProjects pr
	JOIN PurchaseOrders po ON po.project_id = pr.id
	JOIN PurchaseOrders po2 ON po2.project_id = pr.id
	WHERE po.status = 'open'
		AND now!pr.budget > 0 AND after!pr.budget < 0
		AND before!po2.status != after!po2.status
	GROUP BY pr.id, pr.name, pr.budget, po2.id, po2.status, po2.total
	^§AT STEP§ before=817, now=1623, after=2043^
\end{lstlisting}
Like before, the °^AT STEP^° clause does not have to be explicitly typed in the query, but can also be derived from the context.
A language extension allows to add filter conditions that only apply to specific points in time.
\Cref{tab:diffresult} shows a possible result for this query, with one project that goes over budget and two associated purchases, of which one was already processed.\todo{Point not clear - maybe I'm lost because of missing explanation of example}

To produce this result, the query has to be executed three times, once for each point in time, without the time-specific filter conditions.
Then, to prepare the diffing of the results, they are outer-joined on the primary keys and the time-specific filters are applied.
For performance reasons, all of this happens inside a single SQL query, as shown in \cref{lst:tdifffinal}.
The execution of the sub-queries is indicated in \linerefn{lst:tdifffinal}{6, 7, and 10}, the time-specific filters can be found in the Where-condition of \linerefn{lst:tdifffinal}{15 and 16}.

\begin{lstlisting}[language=HanaSQL,float,caption={Parts of the time-diff query after transformation},label=lst:tdifffinal]
	SELECT COALESCE(__before."pr.id", ...) AS "pr.id",
	       COALESCE(__before."po.id", ...) AS "po.id",
				 __before.createdOn as _step_0,
				 __before."pr_name" AS "pr_name_0", ...,
				 ...
	FROM (SELECT ... ^§AT STEP§ before^) __before
	FULL OUTER JOIN (SELECT ... ^§AT STEP§ now^) __now
	    ON __before."pr.id" = __now."pr.id" 
		 AND __before."po.id" = __now."po.id"
	FULL OUTER JOIN (SELECT ... ^§AT STEP§ after^) __after
	    ON (__before."pr.id" = __after."pr.id" 
		      AND __before."po.id" = __after."po.id")
		  OR (__now."pr.id" = __after."pr.id" 
		      AND __now."po.id" = __after."po.id")
	WHERE __now."pr.budget" > 0 AND __after."pr.budget" < 0
	  AND __before."po.status" != __after."po.status"
\end{lstlisting}

For the final result, the key attributes are coalesced while the other attributes are selected from each point in time.
Furthermore, for each tuple its creation step is selected.
This value is needed for two reasons: first, it is necessary to distinguish between tuples with °NULL° values and tuples completely missing from the result; second, it allows the debugger to know when the value was created or changed.

In the UI\todo{Instead of many code listing show the UI (this could also include the code)}, the before and after values are only shown if they differ from the now value.
Clicking on value allows the developer to jump to the °UPDATE° or °INSERT° statement that caused the change.

%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

\section{Evaluation}
\label{sec:evaluation}

We evaluated our \tool\,debugger on a real-world SAP project that has been developed in co-innovation with one of the largest European retail companies. 
This project is called \emph{Point of Sales Explorer}~\cite{plattner2015memory} and allows category managers to see a collection of the most important key performance indicators (KPIs) for several thousands of products in a unified dashboard.
Based on more than 2 billion records of point of sales data, this application aggregates on the fly the requested KPIs with the help of SAP HANA and allows users to further refine them by stores, vendors, or products as they like. 
In order to implement flexible requests such as returning the revenue and margin per week of current and last year, this application makes heavy use of SQLScript. 
For that reason, it is a proper candidate to measure performance and interview its developers with respect to our \tool\ tool. 

\subsection{Performance Measurements}
% bug-tracker 
- Exec time: approx. 3 seconds; with tracing: no measurable overhead\todo{There will be overhead!!! Please measure and discuss - but maybe you can write "no significant overhead" (iff it is below 5\,\%)} \\
- °SELECT * FROM :result°: 1.5 seconds\todo{Hasso will kill you for a select * query - please use realistic example} \\
- \todo{time-diff queries}?


\subsection{Interviews}

Besides measuring performance, we also demonstrated our back-in-time debugger to two backend developers of the Point of Sales Explorer. 
These persons have written most of the SQLScript and so know all the challenges when developing close to the database. 
Both had the chance to apply \tool\, in their daily work while we provided tool support and observed them in the background. 
Finally, we've conducted an in-depth interview in order to receive feedback and further improve our tool.

We found out that the main reason for writing SQLScript is to positively influence the optimizer of SAP HANA in order to speed up the overall user request.
This worked very well as long as the newly written code was bug-free. 
However, if something went wrong at the database-level, the existing tool support was not sufficient. 
They often had to guess why a specific sub query was not as expected. 
For that reason, they liked our back-in-time debugger and we received a lot of positive feedback.
For example, \tool\, could not only show formerly hidden results but also helped them to understand and follow back the reasons behind a failure cause. 
Besides that, both developers also revealed several small bugs in our debugger and wished for some new features such as XXX \todo{please add a specific feature here}.
With this feedback, we see a strong need for better debugging support at the database-level and are eager to further improve our approach.

%\subsection{Threats to Validity}

\subsection{Limitations}

Currently, our approach has two major limitations.

First, time-diff queries can only be executed on tables that have clearly defined primary keys, for key attributes are required to track a tuple's versions over time.b
For a query like "Sum budgets per project category", it has to be clear that categories are the entities that keep their identity over time.
Here, an additional syntax extension could be used to convey this kind of information.

Second, it is currently not possible to use time qualifiers outside of the °WHERE° clause.

%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
%%%---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------


\section{Conclusion}
\label{sec:conclusion}


Future work

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case

\end{document}