% This is "sig-alternate.tex" V2.1 April 2013
% This file should be compiled with V2.5 of "sig-alternate.cls" May 2012
%

\documentclass[english]{sig-alternate-05-2015}



\usepackage{babel}
\usepackage{csquotes}
\MakeOuterQuote{"}

%\usepackage[backend=biber,style=numeric-comp]{biblatex}
%\bibliography{references}
%\renewcommand{\bibliography}[1]{\printbibliography}

\usepackage{MnSymbol}

\usepackage[svgnames]{xcolor}
%\usepackage{todonotes}
%\presetkeys{todonotes}{inline}{}
\usepackage[subject={TODO}]{pdfcomment}
\newcommand{\todo}[2][]{\pdfmargincomment[author={#1}]{#2}}

%\usepackage{makecell}
\usepackage{ctable}


\usepackage{listings}

\newcommand{\lineref}[2]{\hyperref[#1]{line~\ref*{#1:#2}}}
\newcommand{\linerefn}[2]{\hyperref[#1]{line~#2}}
\newcommand{\linesrefn}[2]{\hyperref[#1]{lines~#2}}
\usepackage{accsupp}
\newcommand\emptyaccsupp[1]{\BeginAccSupp{ActualText={}}#1\EndAccSupp{}}

\usepackage{hyperref}
\usepackage[all]{hypcap}
\PassOptionsToPackage{nameinlink,noabbrev}{cleveref}
\usepackage{cleveref}


% \lstset{captionpos=b, xleftmargin=1cm}
\lstset{basicstyle=\small\ttfamily}
\lstset{showstringspaces=false, columns=flexible, keepspaces=true}
\lstset{tabsize=2, gobble=2}
%\lstset{upquote=true}
%% Linebreaks
%\lstset{prebreak=\raisebox{0ex}[0ex][0ex]
%        {\ensuremath{\rhookswarrow}}}
\lstset{postbreak=\raisebox{0ex}[0ex][0ex]{\ensuremath{\rcurvearrowse\space}}}
\lstset{breaklines=true, breakatwhitespace=true}
%% Line Numbers
\newcommand{\lstnumberstyle}[1]{\tiny\emptyaccsupp{#1}}
\lstset{numbers=left, numberstyle=\lstnumberstyle, numbersep=5pt,
		numberfirstline=true, firstnumber=1, stepnumber=5}
\lstset{escapeinside={(*@}{@*)}}
\lstdefinestyle{BWStyle}{
	keywordstyle=\bfseries,
	stringstyle=\color{DimGray},
	commentstyle=\textsl,
}
\lstset{style=BWStyle}

\lstdefinelanguage{algorithm}{
	keywords={function, for, do, if, then, else, return, in_, is_a, or, and},
	morecomment=[l]{'},
	morecomment=[s]{/*}{*/},
	morestring=[b]",  
	sensitive=true,
}
\lstdefinelanguage{HanaSQL}[]{SQL}{
	morekeywords={replace,string,if,is,daysbetween,secondsbetween,weekday,adddays,addseconds,double, procedure,begin,declare,inout,call,return,returns},
	moredelim=**[is][\slshape]{^}{^},
	moredelim=**[is][\bfseries]{§}{§},
}
\lstdefinelanguage{Inline}{
	moredelim=**[is][\slshape]{^}{^},
	moredelim=**[is][\bfseries]{§}{§},
}

\lstset{language=HanaSQL}
\lstMakeShortInline[basicstyle=\ttfamily,language={Inline},breaklines=true]°


\begin{document}

% Copyright
\setcopyright{acmcopyright}
%\setcopyright{acmlicensed}
%\setcopyright{rightsretained}
%\setcopyright{usgov}
%\setcopyright{usgovmixed}
%\setcopyright{cagov}
%\setcopyright{cagovmixed}


% DOI
\doi{10.475/123_4}

% ISBN
\isbn{123-4567-24-567/08/06}

%Conference
\conferenceinfo{PLDI '13}{June 16--19, 2013, Seattle, WA, USA}

\acmPrice{\$15.00}

%
% --- Author Metadata here ---
\conferenceinfo{WOODSTOCK}{'97 El Paso, Texas USA}
%\CopyrightYear{2007} % Allows default copyright year (20XX) to be over-ridden - IF NEED BE.
%\crdata{0-12345-67-8/90/01}  % Allows default copyright data (0-89791-88-6/97/05) to be over-ridden - IF NEED BE.
% --- End of Author Metadata ---

\title{TARDISP: Bringing Back-in-Time Debugging down to the Database}
\subtitle{(TARDISP is a placeholder for the actual name)}
%
% You need the command \numberofauthors to handle the 'placement
% and alignment' of the authors beneath the title.
%
% For aesthetic reasons, we recommend 'three authors at a time'
% i.e. three 'name/affiliation blocks' be placed beneath the title.
%
% NOTE: You are NOT restricted in how many 'rows' of
% "name/affiliations" may appear. We just ask that you restrict
% the number of 'columns' to three.
%
% Because of the available 'opening page real-estate'
% we ask you to refrain from putting more than six authors
% (two rows with three columns) beneath the article title.
% More than six makes the first-page appear very cluttered indeed.
%
% Use the \alignauthor commands to handle the names
% and affiliations for an 'aesthetic maximum' of six authors.
% Add names, affiliations, addresses for
% the seventh etc. author(s) as the argument for the
% \additionalauthors command.
% These 'additional authors' will be output/set for you
% without further effort on your part as the last section in
% the body of your article BEFORE References or any Appendices.

\numberofauthors{3} 
\author{
% 1st. author
\alignauthor
Ben Trovato\titlenote{Dr.~Trovato insisted his name be first.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{1932 Wallamaloo Lane}\\
       \affaddr{Wallamaloo, New Zealand}\\
       \email{trovato@corporation.com}
% 2nd. author
\alignauthor
G.K.M. Tobin\titlenote{The secretary disavows
any knowledge of this author's actions.}\\
       \affaddr{Institute for Clarity in Documentation}\\
       \affaddr{P.O. Box 1212}\\
       \affaddr{Dublin, Ohio 43017-6221}\\
       \email{webmaster@marysville-ohio.com}
% 3rd. author
\alignauthor Lars Th{\o}rv{\"a}ld\titlenote{This author is the
one who did all the really hard work.}\\
       \affaddr{The Th{\o}rv{\"a}ld Group}\\
       \affaddr{1 Th{\o}rv{\"a}ld Circle}\\
       \affaddr{Hekla, Iceland}\\
       \email{larst@affiliation.org}
%\and  % use '\and' if you need 'another row' of author names
}

%\date{30 July 1999}

\maketitle
\begin{abstract}
  Omniscient debuggers allow developers to explore what happened before a failure and so supports them in finding failure causes more efficiently. 
	We present an approach for bringing omniscient debugging to stored procedures that allows to step backwards and query the database at previous points in time.
  Furthermore, we introduce an extension to SQL that allows to express queries covering a period of execution time within a debug session.
	Our prototype implementation is able to debug procedures handling large amounts of data with little overhead on performance and memory.
\end{abstract}

%
% The code below should be generated by the tool at
% http://dl.acm.org/ccs.cfm
% Please copy and paste the code instead of the example below. 
%
\begin{CCSXML}
<ccs2012>
 <concept>
  <concept_id>10010520.10010553.10010562</concept_id>
  <concept_desc>Computer systems organization~Embedded systems</concept_desc>
  <concept_significance>500</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010575.10010755</concept_id>
  <concept_desc>Computer systems organization~Redundancy</concept_desc>
  <concept_significance>300</concept_significance>
 </concept>
 <concept>
  <concept_id>10010520.10010553.10010554</concept_id>
  <concept_desc>Computer systems organization~Robotics</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
 <concept>
  <concept_id>10003033.10003083.10003095</concept_id>
  <concept_desc>Networks~Network reliability</concept_desc>
  <concept_significance>100</concept_significance>
 </concept>
</ccs2012>  
\end{CCSXML}

\ccsdesc[500]{Computer systems organization~Embedded systems}
\ccsdesc[300]{Computer systems organization~Redundancy}
\ccsdesc{Computer systems organization~Robotics}
\ccsdesc[100]{Networks~Network reliability}

\printccsdesc

\keywords{ACM proceedings; \LaTeX; text tagging}

\section{Introduction}

%Context: Debugging and Back-in-Time
Finding defects in code is a frequent task for every programmer and is often difficult even with a deep understanding of the system.
To localize failure causes, they examine involved program entities and distinguish relevant from irrelevant behavior and clean from infected state. 
However, common symbolic debuggers do not support identification of such infection chains very well because they only provide access to the last point of execution without access to the program history.
Back-in-time debuggers simplify the debugging process \todo{cite} by making it easier to follow cause-effect chains from the observable failure back to the causing defect.
These tools provide full access to past events so that developers can directly experiment with the entire infection chain. 

%Problem: Back-in-time debugger missing for database-level
Even though back-in-time debuggers exist for many object-oriented programming languages\todo{cite}, there are none that run on databases and support SQL or SQLScript.
Back-in-time debuggers typically create a significant overhead on performance and memory consumption\todo{cite}.
Thus, it seems unfeasible to use a back-in-time debugger on top of a database script that processes billions of records.
Furthermore, current back-in-time debugging concepts cannot handle side-effects outside their system that usually happen in writing operations during INSERT and UPDATE statements. 

%Significance: Especially, in business software much development is based on database scripts. 
Nevertheless, we argue that back-in-time debugging is also able to speed-up development and reduce maintenance cost of database scripts.
Especially the high performance requirements of big data and business applications demand code to move closer to the database-level\todo{cite}.
With more and more database code, there is also a need to handle the increasing complexity with better debugging tools.
As the existing tools\todo{which one?} are often not adequate because XXX\todo{why}, back-in-time debugging is able to close this gap and supports developers in developing and maintaining SQL statements more efficiently. 


%Solution
In this paper, we bring the concept of back-in-time debugging to the database and present \emph{TARDISP}, an implementation of our approach.
The contributions of this paper are as follows:
\begin{itemize}
	\item \emph{TARDISP} is an omniscient\todo{Either omniscient or back-in-time and then consistent; in the introduction we should write both synonyms once} debugger for stored procedures which can be installed in the SAP HANA in-memory database and programming platform.
		Using TARDISP, developers can move freely through the execution time of a stored procedure and inspect control flow, variables, and intermediate results.
	
	\item \emph{TARDISQL} is an extension to SQL allowing to submit arbitrary queries against previous states of the database 
		and to compare multiple points in time with one query.
		The TARDISP provides a console for developers to submit TARDISQL queries which use variables or points in time from the current debug session.

	\item \emph{Very low overhead} when recording run-time data and the efficient querying of past database states allow developers to use TARDISP as the default tool for debugging database scripts even on larger data sets.
	
\end{itemize}

We evaluated TARDISP within an internal software development project within SAP. \todo{add some more words to project and number of developers}
First interviews with developers indicate that bugs in stored procedures can be investigated more efficiently with TARDISP than with a regular debugger or other database development tools.

The remainder of this paper is structured as follows:
\Cref{sec:prototype} presents our approach and prototype implementation of back-in-time debugging in the database.
\Cref{sec:ttqueries} discusses querying past database states and introduces and extension to SQL.
\Cref{sec:evaluation} evaluates our approach before \cref{sec:conclusion} discusses future work and concludes the paper.

\section{Related Work}

\section{Back-in-time Debugging for Stored Procedures}
\label{sec:prototype}

With a regular debugger, developers have only one way to go back in time, which is to restart the execution.
Tools can be used to automate this approach\todo{cite} and some modern debuggers even allow to restart execution at the method level\todo{cite}.
However, this approach fails if the code has side effects, as it can no longer be guaranteed to execute in the same way.
Furthermore, if the execution is too slow, developers will spend much time waiting for re-execution, which discourages the use of backwards stepping.

A different way to examine a program's behavior over time is to record a trace of the program's actions.
After the program terminated, the trace can be examined in a post-mortem analysis.
This works well for special purpose tools that only analyze a specific aspect of a program, such as profilers.

A post-mortem debugger, on the other hand, would have to trace virtually everything to be able to replay the program execution.
Debugger implementations using this approach exist for different programming languages.

In our work, we focused on stored procedures as database programs, as stored procedures are executed closer to the database and thus more efficient at handling large data sets.
This does not limit the ... of our results, as all code that uses a database creates two challenges for a tracing debugger: 
First, the program's behavior strongly depends on external state, and second, much of the data processing happens outside of the program's scope.
Stored procedures add the additional challenge that results of a query can be used in subsequent database statements without having been fetched into the program.
Thus, data that is crucial for understanding the program is effectively invisible, sometimes only for a few instructions, other times for the entire length of the program.
Furthermore, as trace data usually exceeds program data by orders of magnitude, we expect that tracing the processing of every tuple in a large database is not feasible.


Both approaches can and have been mixed to create a tradeoff between performance and overhead\todo{cite}.




For programs running on an in-memory database, ...

Firstly, the database persists state beyond the program execution.
Even post-mortem, the state can be directly accessed by the debugger.

Secondly, all instructions handling large data sets (i.e., SQL statements), are declarative and reproducible as long as the underlying data does not change.
Thus, SQL queries don't have to be traced at all, although for some purposes it will be helpful to record some meta information, such as the execution time or the number of results.

Thirdly, in-memory databases with insert-only storage automatically retain old data for some time.
With insert-only, older versions of the database can be easily reproduced.
For regular database, insert-only can be achieved by adding validity columns.
For many business applications, the columns already exist as no data may be deleted for legal reasons.

\subsection{Trace Data Model}

To reproduce the execution of a stored procedure, we need to trace a sequence of execution steps.
Each step represents an instruction that has side effects on the database or returns some result to the procedure.
As there is, conceptually, no concurrency in a stored procedure, we can use simple numbering to track the order of steps.
We chose to store all trace data is stored in a relational database.

The debugger distinguishes between 8 types of steps:
three types of control flow steps, for calling, entering and exiting stored procedures;
four kinds of variable assignments for atomic values, query results, cursors, and cursor rows;
and one type for all SQL statements with side-effects.
If applicable, the step has a target name, e.g., the name of a variable or stored procedure, and a string representation of the value, which can be shown to the user in the debug view.

If the step involves a database statement, we store the number of rows in the result set and timestamps from before and after the execution, and atomic argument values, if any.
We never trace any details of the query execution but only record the name of a view than can be used to later reproduce the query result.
The view was specifically generated by the debugger, as will be explained in the next subsection.

\subsection{Reproducing Query Results}

With the recorded trace data, the debugger has enough information available to re-execute any query.
However, the query will only yield the same results as long as the underlying data has not changed.

In general, one can expect that debugging will take place on a development machine where no other data manipulation occurs.
However, in cases where this assumption doesn't hold, the debugger might end up showing wrong or misleading data the developer.
Furthermore, the debugged stored procedure itself may change the data, which will cause a query to return different results at different points in time.

We ensure consistency over time by following the insert-only approach of our in-memory database.
If we require for all tables that data can never be changed or deleted and annotate all tuples with timestamps of when they have been created and invalidated, we can reconstruct the state of the database of any point in time.
Adding timestamp filters to select queries does not cause a significant slowdown.
Our prototype was built using this approach.

\todo{HANA hat seit neustem "History tables" die das direkt können, wir benutzen aber explizite timestamps weil das momentan noch praktischer ist }


\subsection{Prototype and Tracing Code Generation}

- backend: HANA xs-engine \\
- frontend: HTML5 \\

With a debugger fully integrated in its database, we would expect the stored procedure execution engine to trace the execution steps.
However, for our prototype this level of integration was out of scope.

Instead, we wrote a pre-processor in Java that parses a stored procedure and inserts °INSERT° statements around every instruction to collect the required trace data.
To obtain a trace, the debugger then once has to run the traced code instead of the original procedure.

In addition to the tracing code, the pre-processor also generates SQL functions and views that will be used to obtain variable values at given points in time.
For atomic variables, it is simply a search for its most recent step.

For variables containing result tables, a separate view is generated for each query that assigns to that variable.
Each function contains the original code of its query.
Variables used as parameters by the query are initialized using their respective value functions or view.
On top of that, a master view is generated that chooses the appropriate query view based on the requested step and the recorded step data.

%\begin{lstlisting}[language=HanaSQL,float,caption={Example procedure},label=lst:example]
	%CREATE PROCEDURE Check_Projects_Of_Department(dep_name VARCHAR(100)) AS
	%BEGIN
		%DECLARE dep_id INTEGER := SELECT id FROM Deparments WHERE name = :dep_name;
		%selected_projects := SELECT id FROM Projects WHERE deparment = :dep_id;
		%CALL Check_Projects(:selected_projects);
	%END
%\end{lstlisting}

%\begin{lstlisting}[language=HanaSQL,float,caption={Procedure with tracing},label=lst:example2]
	%CREATE PROCEDURE _T__Check_Projects_Of_Department (IN __t_id INT, IN __ce_id INT, INOUT __s_id INT, dep_name VARCHAR(100)) AS
	%BEGIN
		%DECLARE __e_id INT := __s_id+1;
		%DECLARE __ts TIMESTAMP;
		%DECLARE __count INT;
%
		%DECLARE dep_id INTEGER := SELECT id FROM Deparments WHERE name = :dep_name;
		%/*  1*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id+1,:__ce_id,'ENTER', 'Check_Projects_Of_Department',NULL,1);
		%/*  1*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id+1,:__e_id,'VARIABLE', 'dep_name',:dep_name,1);
		%/*  3*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id+2,:__e_id,'VARIABLE',  'dep_id',:dep_id,3);
		%__s_id := __s_id + 3;
		%/*  4*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id,:__e_id,'QUERY', 'selected_projects','selected_projects := SELECT id FROM Projects WHERE deparment = :dep_id;',4);
		%/*   */ __ts := NOW();
		%selected_projects := SELECT id FROM Projects WHERE deparment = :dep_id;
		%/*   */ SELECT COUNT(*) INTO __count FROM :selected_projects;
		%/*  4*/ INSERT INTO Quid_Accidit.Queries (trace_id,step,query,count,pre,post) VALUES (:__t_id,:__s_id, '_selected_projects_4_Check_Projects_Of_Department', __count,__ts,NOW());
		%__s_id := __s_id + 1;
		%/*  5*/ INSERT INTO Quid_Accidit.Steps (trace_id,step,entry_step,type,target,value,line) VALUES (:__t_id,:__s_id,:__e_id,'CALL', '?','Check_Projects',5);
		%CALL _T__Check_Projects(__s_id, :selected_projects);
	%END;
%
	%CREATE PROCEDURE _TE_Check_Projects_Of_Department (dep_name VARCHAR(100)) AS
	%BEGIN
		%DECLARE __t_id INT;
		%DECLARE __s_id INT DEFAULT 0;
		%SELECT COALESCE(MAX(id),0)+1 INTO __t_id FROM Quid_Accidit.Traces;
		%INSERT INTO Quid_Accidit.Traces(id, name) VALUES (:__t_id, 'Check_Projects_Of_Department');
		%CALL _T__Check_Projects_Of_Department (:__t_id, 0, __s_id, dep_name);
	%END;
%\end{lstlisting}

\begin{lstlisting}[language=HanaSQL,float,caption={Example query in line 4 of "Check\_Projects"},label=lst:example3]
	selected_projects := SELECT p.id FROM Projects p WHERE p.deparment = :dep_id;
\end{lstlisting}

\begin{lstlisting}[language=HanaSQL,float,caption={Query view},label=lst:example4]
	CREATE FUNCTION 
			_Q__Check_Projects_selected_projects_4_ 
			(IN trace_id INT, IN step INT)
	RETURNS TABLE(id INT) 
			LANGUAGE SQLSCRIPT AS
	BEGIN
		DECLARE __ts TIMESTAMP := 
				SELECT before FROM Queries q 
				WHERE q.trace_id = :trace_id 
				  AND q.step = :step;
		DECLARE dep_id INT := SELECT 
				_V__Check_Projects_dep_id_(:trace_id, :step) 
				FROM DUMMY;
		RETURN SELECT p.id FROM Projects p
				WHERE p.deparment = :dep_id
				  AND p.created_on < __ts
					AND (p.valid_until IS NULL 
					   OR p.valid_until > __ts);
	END;
\end{lstlisting}


\section{Time-travel Queries}
\label{sec:ttqueries}

In our set-up, the debugger trying to recreate intermediate results of a stored procedure is just a special use case for the ability to submit arbitrary queries against the database of any previous point in time.

\subsection{The Step Concept}

The query shown in \cref{lst:ttravel} selects the total of open orders for previously selected projects.
We will use it as an example to demonstrate how \emph{time-traveling} queries are handled by our system.

\begin{lstlisting}[language=HanaSQL,float,caption={Example for a time-travel query: select the current total of open orders for previously selected projects},label=lst:ttravel]
  SELECT pr.id, pr.name, pr.budget, SUM(po.total)
  FROM :selected_projects pr
	JOIN PurchaseOrders po ON po.project_id = pr.id
	WHERE po.status = 'open'
	GROUP BY pr.id, pr.name, pr.budget
	^§AT STEP§ 1623^
\end{lstlisting}

The last line shows an extension to SQL that can be used by the developer to explicitly query a point in time, with °^1623^° being a step ID that was obtained from the debugger UI.
If omitted, the current step can be derived from the context from which the query is submitted, such as an SQL console that is associated with a specific point in time or the current debug step.
The parameter °:selected_projects° refers to a variable from the current debug session and will be populated with its current value, independently of the value of the step-clause.

When submitted, our debugger applies two changes to the query before it can be submitted to the database.
First, all variables are replaced with corresponding functions or views.
For variables containing atomic values, a function is generated that returns the variable's value at a given step.
For variables containing query results, a view is generated for each query.
These views are identified by the target variable name and the line number and expect a step number and all parameters that the actual query took.
\todo{explain variable functions}
In our example, °:selected_projects° might be replaced with °VAR_selected_projects_7(1055, 'Research')° when it was last set at step 1055 in code line 7 and called with the respective argument.

Second, a time-stamp filter is added for all tables that are referenced in the query. 
In our example,
\begin{lstlisting}[language={Inline},basicstyle=\ttfamily,numbers=none]
  po.createdOn < ^1623^ AND (po.validTo IS NULL OR po.validTo > ^1623^)
\end{lstlisting}
would be added to the Where-clause.

Now, the query can be submitted to the database and the result is subsequently presented to the user.

\subsection{Time-diff Queries}

\newcommand{\red}[1]{\textcolor{DarkRed}{#1}}
\newcommand{\gr}[1]{\textcolor{Green}{#1}}


\ctable[star,caption={Result of a time-diff query, with multiple values in some columns},label=tab:diffresult,doinside={}]
				{rlrrrlr}{}{
	pr.id & pr.name 	& pr.budget & total & po2.id & po2.status & po2.total \ML
	
				&					 & \red{1200} & \red{1500} &	 & \red{open} &						\NN
	1			& Project 1 & 200				& 500 			 & 1 & paid 			& 1000			\NN
				&						& \gr{-300} & \gr{0}		 &	 &						&						\ML

				&					 & \red{1200} & \red{1500} &	 & 						&						\NN
	1			& Project 1 & 200				& 500 			 & 2 & open 			& 500				\NN
				&						& \gr{-300} & \gr{0}		 &	 & \gr{paid}	&						\ML
}

To get a better overview about what happened in a piece of code, the developer might want to query multiple points in time at once and see the difference in the query result.
For this example, she debugs a stored procedure that processes the payments for projects, but sometimes allows projects to go over budget.
By stepping into the procedure, she has three defined points in time: °^before^°, at the beginning of the procedure; °^now^°, at the current instruction; and °^after^°, at the end of the execution.

Now she wants to compose a query that selects all projects that will go over budget and the orders that were processed.
\todo{explain query rewriting}
The query is shown in \cref{lst:tdiff}.
\begin{lstlisting}[language=HanaSQL,float=b,caption={Example of a time-diff query: "Select all projects that will go over budget and their respective purchase orders"},label=lst:tdiff]
	SELECT pr.id, pr.name, pr.budget, SUM(po.total), po2.id, po2.status, po2.total
	FROM :selectedProjects pr
	JOIN PurchaseOrders po ON po.project_id = pr.id
	JOIN PurchaseOrders po2 ON po2.project_id = pr.id
	WHERE po.status = 'open'
		AND now!pr.budget > 0 AND after!pr.budget < 0
		AND before!po2.status != after!po2.status
	GROUP BY pr.id, pr.name, pr.budget, po2.id, po2.status, po2.total
	^§AT STEP§ before=817, now=1623, after=2043^
\end{lstlisting}
Like before, the °^AT STEP^° clause does not have to be explicitly typed in the query, but can also be derived from the context.
A language extension allows to add filter conditions that only apply to specific points in time.
\Cref{tab:diffresult} shows a possible result for this query, with one project that goes over budget and two associated purchases, of which one was already processed.

To produce this result, the query has to be executed three times, once for each point in time, without the time-specific filter conditions.
Then, to prepare the diffing of the results, they are outer-joined on the primary keys and the time-specific filters are applied.
For performance reasons, all of this happens inside a single SQL query, as shown in \cref{lst:tdifffinal}.
The execution of the sub-queries is indicated in \linerefn{lst:tdifffinal}{6, 7, and 10}, the time-specific filters can be found in the Where-condition of \linerefn{lst:tdifffinal}{15 and 16}.

\begin{lstlisting}[language=HanaSQL,float,caption={Parts of the time-diff query after transformation},label=lst:tdifffinal]
	SELECT COALESCE(__before."pr.id", ...) AS "pr.id",
	       COALESCE(__before."po.id", ...) AS "po.id",
				 __before.createdOn as _step_0,
				 __before."pr_name" AS "pr_name_0", ...,
				 ...
	FROM (SELECT ... ^§AT STEP§ before^) __before
	FULL OUTER JOIN (SELECT ... ^§AT STEP§ now^) __now
	    ON __before."pr.id" = __now."pr.id" 
		 AND __before."po.id" = __now."po.id"
	FULL OUTER JOIN (SELECT ... ^§AT STEP§ after^) __after
	    ON (__before."pr.id" = __after."pr.id" 
		      AND __before."po.id" = __after."po.id")
		  OR (__now."pr.id" = __after."pr.id" 
		      AND __now."po.id" = __after."po.id")
	WHERE __now."pr.budget" > 0 AND __after."pr.budget" < 0
	  AND __before."po.status" != __after."po.status"
\end{lstlisting}

For the final result, the key attributes are coalesced while the other attributes are selected from each point in time.
Furthermore, for each tuple its creation step is selected.
This value is needed for two reasons: first, it is necessary to distinguish between tuples with °NULL° values and tuples completely missing from the result; second, it allows the debugger to know when the value was created or changed.

In the UI, the before and after values are only shown if they differ from the now value.
Clicking on value allows the developer to jump to the °UPDATE° or °INSERT° statement that caused the change.

\section{Evaluation}
\label{sec:evaluation}

- Test system: 2 billion records of point of sales data \\
- Stored procedure: calculate revenue and margin per week of current and last year \\
- Exec time: approx. 3 seconds; with tracing: no measurable overhead \\
- °SELECT * FROM :result°: 1.5 seconds \\
- \todo{time-diff queries}?

% bug-tracker 

\subsection{Limitations}

Currently, our approach has two major limitations.

First, time-diff queries can only be executed on tables that have clearly defined primary keys, for key attributes are required to track a tuple's versions over time.b
For a query like "Sum budgets per project category", it has to be clear that categories are the entities that keep their identity over time.
Here, an additional syntax extension could be used to convey this kind of information.

Second, it is currently not possible to use time qualifiers outside of the °WHERE° clause.


\section{Conclusion}
\label{sec:conclusion}


Future work

%
% The following two commands are all you need in the
% initial runs of your .tex file to
% produce the bibliography for the citations in your paper.
\bibliographystyle{abbrv}
\bibliography{sigproc}  % sigproc.bib is the name of the Bibliography in this case

\end{document}